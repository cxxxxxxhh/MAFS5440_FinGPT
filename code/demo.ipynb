{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecaster and Portfolio Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 16:21:08.056289: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-03 16:21:08.130713: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733214068.180823  564351 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733214068.195600  564351 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-03 16:21:08.244755: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4d4fa4e1b74fb8abdd03cac1448022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f755927dad37421f960e8ec9a637efac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ca52b82d8245739b20c126a3be7597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import finnhub\n",
    "import torch\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from pynvml import *\n",
    "from peft import PeftModel\n",
    "from collections import defaultdict\n",
    "from datetime import date, datetime, timedelta\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
    "\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = \"\"\n",
    "\n",
    "os.environ[\"FINNHUB_API_KEY\"] = \"\"\n",
    "\n",
    "access_token = os.environ[\"HF_TOKEN\"]\n",
    "\n",
    "\n",
    "finnhub_client = finnhub.Client(api_key=os.environ[\"FINNHUB_API_KEY\"])\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    '/checkpoints/Llama-2-7b-chat-hf',\n",
    "    token=access_token,\n",
    "    trust_remote_code=False, \n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16, \n",
    ")\n",
    "model_strategy = AutoModelForCausalLM.from_pretrained(\n",
    "    '/FinGPT_Strategy/finetuned_models/strategy-train_202411251624/checkpoint-104',\n",
    "    trust_remote_code=False,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,  \n",
    "    token = \"\",\n",
    "    offload_folder=\"/FinGPT_Strategy/offload/\" \n",
    ")\n",
    "\n",
    "model_strategy = model_strategy.eval()\n",
    "\n",
    "model_forecast = AutoModelForCausalLM.from_pretrained(\n",
    "    '/FinGPT_Forecaster/finetuned_models/local-test_202411211516/checkpoint-88',\n",
    "    trust_remote_code=False,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,  \n",
    "    token = \"\",\n",
    ")\n",
    "\n",
    "model_forecast = model_forecast.eval()\n",
    "\n",
    "tokenizer_strategy = AutoTokenizer.from_pretrained(\n",
    "    '/FinGPT_Strategy/finetuned_models/strategy-train_202411251624/checkpoint-104',\n",
    "    token=access_token\n",
    ")\n",
    "\n",
    "tokenizer_forecast = AutoTokenizer.from_pretrained(\n",
    "    '/FinGPT_Forecaster/finetuned_models/local-test_202411211516/checkpoint-88',\n",
    "    token=access_token\n",
    ")\n",
    "\n",
    "streamer_strategy = TextStreamer(tokenizer_strategy)\n",
    "streamer_forecast = TextStreamer(tokenizer_forecast)\n",
    "\n",
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "\n",
    "SYSTEM_PROMPT_FORECAST = \"You are a seasoned stock market analyst. Your task is to list the positive developments and potential concerns for companies based on relevant news and basic financials from the past weeks, then provide an analysis and prediction for the companies' stock price movement for the upcoming week. \" \\\n",
    "    \"Your answer format should be as follows:\\n\\n[Positive Developments]:\\n1. ...\\n\\n[Potential Concerns]:\\n1. ...\\n\\n[Prediction & Analysis]\\nPrediction: ...\\nAnalysis: ...\"\n",
    "\n",
    "SYSTEM_PROMPT_STRATEGY = \"You are a seasoned stock market analyst. Your task is to construct a portfolio including weights of these stocks based  on relevant news and basic financials from the past weeks, then provide an explanation of why did you choose these weights. \" \\\n",
    "    \"Your answer format should be as follows:\\n\\n[Portfolio Weights]:\\n1. ... (stock name) - ...% (weight)\\n\\n[Explanation]\\n1. ...\\n\\n[Risk Management]\\n1. ...\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gpu_utilization():\n",
    "    \n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")  \n",
    "\n",
    "\n",
    "def get_curday():\n",
    "    \n",
    "    return date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def n_weeks_before(date_string, n):\n",
    "    \n",
    "    date = datetime.strptime(date_string, \"%Y-%m-%d\") - timedelta(days=7*n)\n",
    "\n",
    "    return date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def get_stock_data(stock_symbol, steps):\n",
    "\n",
    "    stock_data = yf.download(stock_symbol, steps[0], steps[-1]) #step[0] is the start date, step[-1] is the end date\n",
    "\n",
    "    \n",
    "    \n",
    "    if len(stock_data) == 0:\n",
    "        raise gr.Error(f\"Failed to download stock price data for symbol {stock_symbol} from yfinance!\")\n",
    "    \n",
    "    dates, prices = [], []\n",
    "    available_dates = stock_data.index.format() \n",
    "    #print(available_dates)\n",
    "    \n",
    "    for date in steps[:-1]: # 每天每个股票，如果有数据就加入，没有就跳过\n",
    "        for i in range(len(stock_data)):\n",
    "            if available_dates[i] >= date:\n",
    "                prices.append(stock_data['Close'].iloc[i].values[0])\n",
    "                dates.append(datetime.strptime(available_dates[i][:10], \"%Y-%m-%d\"))\n",
    "                #print(dates)\n",
    "                break\n",
    "\n",
    "    dates.append(datetime.strptime(available_dates[-1][:10], \"%Y-%m-%d\"))\n",
    "    #print(dates)\n",
    "    prices.append(stock_data['Close'].iloc[-1].values[0])\n",
    "\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        \"Start Date\": dates[:-1], \"End Date\": dates[1:],\n",
    "        \"Start Price\": prices[:-1], \"End Price\": prices[1:]\n",
    "    })\n",
    "\n",
    "\n",
    "def get_news(symbol, data):\n",
    "    \n",
    "    news_list = []\n",
    "    \n",
    "    for end_date, row in data.iterrows():\n",
    "        start_date = row['Start Date'].strftime('%Y-%m-%d')\n",
    "        end_date = row['End Date'].strftime('%Y-%m-%d')\n",
    "#         print(symbol, ': ', start_date, ' - ', end_date)\n",
    "        time.sleep(1) # control qpm\n",
    "        weekly_news = finnhub_client.company_news(symbol, _from=start_date, to=end_date)\n",
    "        if len(weekly_news) == 0:\n",
    "            raise gr.Error(f\"No company news found for symbol {symbol} from finnhub!\")\n",
    "        weekly_news = [\n",
    "            {\n",
    "                \"date\": datetime.fromtimestamp(n['datetime']).strftime('%Y%m%d%H%M%S'),\n",
    "                \"headline\": n['headline'],\n",
    "                \"summary\": n['summary'],\n",
    "            } for n in weekly_news\n",
    "        ]\n",
    "        weekly_news.sort(key=lambda x: x['date'])\n",
    "        news_list.append(json.dumps(weekly_news))\n",
    "    \n",
    "    data['News'] = news_list\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def get_company_prompt(symbol):\n",
    "\n",
    "    profile = finnhub_client.company_profile2(symbol=symbol)\n",
    "    if not profile:\n",
    "        raise gr.Error(f\"Failed to find company profile for symbol {symbol} from finnhub!\")\n",
    "        \n",
    "    company_template = \"[Company Introduction]:\\n\\n{name} is a leading entity in the {finnhubIndustry} sector. Incorporated and publicly traded since {ipo}, the company has established its reputation as one of the key players in the market. As of today, {name} has a market capitalization of {marketCapitalization:.2f} in {currency}, with {shareOutstanding:.2f} shares outstanding.\" \\\n",
    "        \"\\n\\n{name} operates primarily in the {country}, trading under the ticker {ticker} on the {exchange}. As a dominant force in the {finnhubIndustry} space, the company continues to innovate and drive progress within the industry.\"\n",
    "\n",
    "    formatted_str = company_template.format(**profile)\n",
    "    \n",
    "    return formatted_str\n",
    "\n",
    "\n",
    "def get_prompt_by_row(symbol, row):\n",
    "\n",
    "    start_date = row['Start Date'] if isinstance(row['Start Date'], str) else row['Start Date'].strftime('%Y-%m-%d')\n",
    "    end_date = row['End Date'] if isinstance(row['End Date'], str) else row['End Date'].strftime('%Y-%m-%d')\n",
    "    term = 'increased' if row['End Price'] > row['Start Price'] else 'decreased'\n",
    "    head = \"From {} to {}, {}'s stock price {} from {:.2f} to {:.2f}. Company news during this period are listed below:\\n\\n\".format(\n",
    "        start_date, end_date, symbol, term, row['Start Price'], row['End Price'])\n",
    "    \n",
    "    news = json.loads(row[\"News\"])\n",
    "    news = [\"[Headline]: {}\\n[Summary]: {}\\n\".format(\n",
    "        n['headline'], n['summary']) for n in news if n['date'][:8] <= end_date.replace('-', '') and \\\n",
    "        not n['summary'].startswith(\"Looking for stock market analysis and research with proves results?\")]\n",
    "\n",
    "    basics = json.loads(row['Basics'])\n",
    "    if basics:\n",
    "        basics = \"Some recent basic financials of {}, reported at {}, are presented below:\\n\\n[Basic Financials]:\\n\\n\".format(\n",
    "            symbol, basics['period']) + \"\\n\".join(f\"{k}: {v}\" for k, v in basics.items() if k != 'period')\n",
    "    else:\n",
    "        basics = \"[Basic Financials]:\\n\\nNo basic financial reported.\"\n",
    "    \n",
    "    return head, news, basics\n",
    "\n",
    "\n",
    "def sample_news(news, k=5):\n",
    "    \n",
    "    return [news[i] for i in sorted(random.sample(range(len(news)), k))]\n",
    "\n",
    "\n",
    "def get_current_basics(symbol, curday): # get the most recent basic financials\n",
    "\n",
    "    basic_financials = finnhub_client.company_basic_financials(symbol, 'all')\n",
    "    if not basic_financials['series']:\n",
    "        raise gr.Error(f\"Failed to find basic financials for symbol {symbol} from finnhub!\")\n",
    "        \n",
    "    final_basics, basic_list, basic_dict = [], [], defaultdict(dict)\n",
    "    \n",
    "    for metric, value_list in basic_financials['series']['quarterly'].items():\n",
    "        for value in value_list:\n",
    "            basic_dict[value['period']].update({metric: value['v']})\n",
    "\n",
    "    for k, v in basic_dict.items():\n",
    "        v.update({'period': k})\n",
    "        basic_list.append(v)\n",
    "        \n",
    "    basic_list.sort(key=lambda x: x['period'])\n",
    "    \n",
    "    for basic in basic_list[::-1]:\n",
    "        if basic['period'] <= curday:\n",
    "            break\n",
    "            \n",
    "    return basic\n",
    "    \n",
    "\n",
    "def get_all_prompts_online(symbol, data, curday, with_basics=True):\n",
    "\n",
    "    company_prompt = get_company_prompt(symbol)\n",
    "\n",
    "    prev_rows = []\n",
    "\n",
    "    for row_idx, row in data.iterrows():\n",
    "        head, news, _ = get_prompt_by_row(symbol, row)\n",
    "        prev_rows.append((head, news, None))\n",
    "        \n",
    "    prompt = \"\"\n",
    "    for i in range(-len(prev_rows), 0):\n",
    "        prompt += \"\\n\" + prev_rows[i][0]\n",
    "        sampled_news = sample_news(\n",
    "            prev_rows[i][1],\n",
    "            min(5, len(prev_rows[i][1]))\n",
    "        )\n",
    "        if sampled_news:\n",
    "            prompt += \"\\n\".join(sampled_news)\n",
    "        else:\n",
    "            prompt += \"No relative news reported.\"\n",
    "        \n",
    "    period = \"{} to {}\".format(curday, n_weeks_before(curday, -1))\n",
    "    \n",
    "    if with_basics:\n",
    "        basics = get_current_basics(symbol, curday)\n",
    "        basics = \"Some recent basic financials of {}, reported at {}, are presented below:\\n\\n[Basic Financials]:\\n\\n\".format(\n",
    "            symbol, basics['period']) + \"\\n\".join(f\"{k}: {v}\" for k, v in basics.items() if k != 'period')\n",
    "    else:\n",
    "        basics = \"[Basic Financials]:\\n\\nNo basic financial reported.\"\n",
    "\n",
    "    info = company_prompt + '\\n' + prompt + '\\n' + basics\n",
    "    prompt = info + f\"\\n\\nLet's guess your prediction for next week of {symbol} ({period}). \" \\\n",
    "        \"The prediction result need to be inferred from your analysis at the end, and thus not appearing as a foundational factor of your analysis.\" \n",
    "        \n",
    "    return info, prompt\n",
    "\n",
    "\n",
    "def construct_prompt_forecast(ticker, curday, n_weeks, use_basics):\n",
    "\n",
    "    try:\n",
    "        steps = [n_weeks_before(curday, n) for n in range(n_weeks + 1)][::-1]\n",
    "    except Exception:\n",
    "        raise gr.Error(f\"Invalid date {curday}!\")\n",
    "        \n",
    "    data = get_stock_data(ticker, steps)\n",
    "    data = get_news(ticker, data)\n",
    "    data['Basics'] = [json.dumps({})] * len(data)\n",
    "    # print(data)\n",
    "    \n",
    "    info, prompt = get_all_prompts_online(ticker, data, curday, use_basics)\n",
    "    \n",
    "    prompt = B_INST + B_SYS + SYSTEM_PROMPT_FORECAST + E_SYS + prompt + E_INST\n",
    "    # print(prompt)\n",
    "    \n",
    "    return info, prompt\n",
    "# def get_all_prompts_online_strategy(portfolio, curday, n_weeks, with_basics=True):\n",
    "#     all_prompt = \"\"\n",
    "#     for stock in portfolio:\n",
    "#         all_prompt += construct_prompt(stock, curday, n_weeks, with_basics)[1]\n",
    "#     all_prompt = B_INST + B_SYS + SYSTEM_PROMPT_STRATEGY + E_SYS + all_prompt + E_INST\n",
    "#     return all_prompt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_all_prompts_online_strategy(symbol_list, date, n_weeks, with_basics=True):\n",
    "\n",
    "    info = \"\"\n",
    "    for symbol in symbol_list:\n",
    "\n",
    "        company_prompt = get_company_prompt(symbol)\n",
    "\n",
    "        try:\n",
    "            steps = [n_weeks_before(date, n) for n in range(n_weeks + 1)][::-1]\n",
    "        except Exception:\n",
    "            raise gr.Error(f\"Invalid date {date}!\")\n",
    "        \n",
    "        data = get_stock_data(symbol, steps)\n",
    "        data = get_news(symbol, data)\n",
    "        data['Basics'] = [json.dumps({})] * len(data)\n",
    "\n",
    "        prev_rows = []\n",
    "\n",
    "        for row_idx, row in data.iterrows():\n",
    "            head, news, _ = get_prompt_by_row(symbol, row)\n",
    "            prev_rows.append((head, news, None))\n",
    "            \n",
    "        prompt = \"\"\n",
    "        for i in range(-len(prev_rows), 0):\n",
    "            prompt += \"\\n\" + prev_rows[i][0]\n",
    "            sampled_news = sample_news(\n",
    "                prev_rows[i][1],\n",
    "                min(5, len(prev_rows[i][1]))\n",
    "            )\n",
    "            if sampled_news:\n",
    "                prompt += \"\\n\".join(sampled_news)\n",
    "            else:\n",
    "                prompt += \"No relative news reported.\"\n",
    "            \n",
    "        period = \"{} to {}\".format(date, n_weeks_before(date, -1))\n",
    "        \n",
    "        if with_basics:\n",
    "            basics = get_current_basics(symbol, date)\n",
    "            basics = \"Some recent basic financials of {}, reported at {}, are presented below:\\n\\n[Basic Financials]:\\n\\n\".format(\n",
    "                symbol, basics['period']) + \"\\n\".join(f\"{k}: {v}\" for k, v in basics.items() if k != 'period')\n",
    "        else:\n",
    "            basics = \"[Basic Financials]:\\n\\nNo basic financial reported.\"\n",
    "\n",
    "        info = info + '\\n' + symbol + '\\n' + company_prompt + '\\n' + prompt + '\\n' + basics\n",
    "    prompt = info + f\"\\n\\nBased on all the information before {date}, let's first make a portfolio with specific weights. \"  \\\n",
    "                    f\"Provide a summary analysis to support your prediction.\"\n",
    "        \n",
    "    return info, prompt\n",
    "\n",
    "def process_prompt(prompt):\n",
    "    paragraphs = prompt.split(\"\\n\\n\")\n",
    "        # 使用集合去重\n",
    "    unique_paragraphs = set(paragraphs)\n",
    "    # 将唯一段落重新组合成字符串\n",
    "    result = \"\\n\\n\".join(unique_paragraphs)\n",
    "    return result  # 示例操作：去除前后空格\n",
    "\n",
    "def construct_prompt_strategy(symbol_list, curday, n_weeks, use_basics):\n",
    "    # print(data)\n",
    "    \n",
    "    info, prompt = get_all_prompts_online_strategy(symbol_list, curday, n_weeks, use_basics)\n",
    "\n",
    "    prompt = process_prompt(prompt)\n",
    "    \n",
    "    print(len(prompt))\n",
    "    prompt = B_INST + B_SYS + SYSTEM_PROMPT_STRATEGY + E_SYS + prompt + E_INST\n",
    "    # print(prompt)\n",
    "    \n",
    "    return info, prompt\n",
    "\n",
    "def predict_strategy(tickers, date, n_weeks, use_basics):\n",
    "\n",
    "    print_gpu_utilization()\n",
    "\n",
    "    tickers = [ticker.strip() for ticker in tickers.split(',')]\n",
    "\n",
    "    info, prompt = construct_prompt_strategy(tickers, date, n_weeks, use_basics)\n",
    "    \n",
    "      \n",
    "    inputs = tokenizer_strategy(\n",
    "        prompt, return_tensors='pt', padding=False\n",
    "    )\n",
    "    inputs = {key: value.to(model_strategy.device) for key, value in inputs.items()}\n",
    "\n",
    "    print(\"Inputs loaded onto devices.\")\n",
    "        \n",
    "    res = model_strategy.generate(\n",
    "        **inputs, do_sample=True,\n",
    "        #max_length=2048*10, \n",
    "        eos_token_id=tokenizer_strategy.eos_token_id,\n",
    "        use_cache=True, streamer=streamer_strategy\n",
    "    )\n",
    "    output = tokenizer_strategy.decode(res[0], skip_special_tokens=True)\n",
    "    answer = re.sub(r'.*\\[/INST\\]\\s*', '', output, flags=re.DOTALL)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return info, answer, None, None\n",
    "\n",
    "def predict_forecast(ticker, date, n_weeks, use_basics):\n",
    "\n",
    "    print_gpu_utilization()\n",
    "\n",
    "    info, prompt = construct_prompt_forecast(ticker, date, n_weeks, use_basics)\n",
    "      \n",
    "    inputs = tokenizer_forecast(\n",
    "        prompt, return_tensors='pt', padding=False\n",
    "    )\n",
    "    inputs = {key: value.to(model_forecast.device) for key, value in inputs.items()}\n",
    "\n",
    "    print(\"Inputs loaded onto devices.\")\n",
    "        \n",
    "    res = model_forecast.generate(\n",
    "        **inputs, max_length=2048*8, do_sample=True,\n",
    "        eos_token_id=tokenizer_forecast.eos_token_id,\n",
    "        use_cache=True, streamer=streamer_forecast\n",
    "    )\n",
    "    output = tokenizer_forecast.decode(res[0], skip_special_tokens=True)\n",
    "    answer = re.sub(r'.*\\[/INST\\]\\s*', '', output, flags=re.DOTALL)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return info, answer, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import accelerate\n",
    "# import bitsandbytes\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import finnhub\n",
    "import torch\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from pynvml import *\n",
    "from peft import PeftModel\n",
    "from collections import defaultdict\n",
    "from datetime import date, datetime, timedelta\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForCausalLM, LlamaForCausalLM, LlamaTokenizerFast   # 4.30.2\n",
    "from peft import PeftModel  # 0.4.0\n",
    "import torch\n",
    "\n",
    "finnhub_client = finnhub.Client(api_key=\"\")\n",
    "\n",
    "\n",
    "sys.path.append('/project3_LLM/FinGPT/fingpt/FinNLP')\n",
    "\n",
    "base_model_senti = \"NousResearch/Llama-2-13b-hf\" \n",
    "peft_model_senti = \"FinGPT/fingpt-sentiment_llama2-13b_lora\"\n",
    "model_senti = LlamaForCausalLM.from_pretrained(base_model_senti, trust_remote_code=True, offload_folder=\"offload/\",\n",
    "                                               load_in_8bit = True,\n",
    "                                            \n",
    "                                               )\n",
    "\n",
    "tokenizer_senti = AutoTokenizer.from_pretrained(base_model_senti, trust_remote_code=True)\n",
    "\n",
    "model_senti = PeftModel.from_pretrained(model_senti, peft_model_senti,\n",
    "                                        offload_folder=\"offload/\")\n",
    "model_senti = model_senti.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def n_weeks_before(date_string, n):\n",
    "    \n",
    "    date = datetime.strptime(date_string, \"%Y-%m-%d\") - timedelta(days=7*n)\n",
    "\n",
    "    return date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def analyze_sentiment(news_list, tokenizer_senti, model_senti):\n",
    "    results = []\n",
    "    for news in news_list:\n",
    "        # 构建提示词\n",
    "        prompt = f\"\"\"Instruction: What is the sentiment of this news? Please choose an answer from {{negative/neutral/positive}}\n",
    "Input: {news['headline']} {news['summary']}\n",
    "Answer: \"\"\"\n",
    "        \n",
    "        # 分词和编码\n",
    "        tokens_senti = tokenizer_senti(prompt, return_tensors=\"pt\", padding=True, max_length=512)\n",
    "        \n",
    "        # 调用情感分析模型\n",
    "        outputs = model_senti.generate(**tokens_senti, max_length=512)\n",
    "        sentiment = tokenizer_senti.decode(outputs[0], skip_special_tokens=True).split(\"Answer: \")[-1].strip().lower()\n",
    "        \n",
    "        # 检查情感结果是否有效\n",
    "        if sentiment not in {\"positive\", \"neutral\", \"negative\"}:\n",
    "            sentiment = \"unknown\"  \n",
    "        \n",
    "        # 保存结果\n",
    "        results.append({\"headline\": news['headline'], \"summary\": news['summary'], \"sentiment\": sentiment})\n",
    "    return results\n",
    "\n",
    "def fetch_and_analyze_news(ticker, tokenizer_senti, model_senti,date, n_weeks):\n",
    "\n",
    "    news = finnhub_client.company_news(ticker, _from=n_weeks_before(date, n_weeks), to=date)\n",
    "    news = news[:20]  # 只取最近 20 条新闻\n",
    "    \n",
    "    # 进行情感分析\n",
    "    analyzed_news = analyze_sentiment(news, tokenizer_senti, model_senti)\n",
    "    \n",
    "    # 初始化统计字典\n",
    "    sentiment_stats = {\"positive\": 0, \"neutral\": 0, \"negative\": 0}\n",
    "    for item in analyzed_news:\n",
    "        if item[\"sentiment\"] in sentiment_stats:  # 确保情感结果有效\n",
    "            sentiment_stats[item[\"sentiment\"]] += 1\n",
    "\n",
    "    return sentiment_stats, analyzed_news\n",
    "\n",
    "\n",
    "def predict_sentiment(ticker, date, n_weeks):\n",
    "\n",
    "    sentiment_stats, analyzed_news = fetch_and_analyze_news(ticker, tokenizer_senti, model_senti, date, n_weeks)\n",
    "    \n",
    "    # 生成结果文本\n",
    "    sentiment_report = f\"Sentiment Analysis for {ticker}:\\n\"\n",
    "    sentiment_report += f\"Positive: {sentiment_stats['positive']} | Neutral: {sentiment_stats['neutral']} | Negative: {sentiment_stats['negative']}\\n\\n\"\n",
    "    sentiment_report += \"Detailed News Sentiment:\\n\"\n",
    "    for news in analyzed_news:\n",
    "        sentiment_report += f\"- [Headline]: {news['headline']}\\n  [Sentiment]: {news['sentiment']}\\n\\n\"\n",
    "    \n",
    "    labels = ['Positive', 'Neutral', 'Negative']\n",
    "    counts = [sentiment_stats['positive'], sentiment_stats['neutral'], sentiment_stats['negative']]\n",
    "    colors = ['#FCB44A', '#4DBB82', '#403292']\n",
    "    \n",
    "    data = {'Sentiment': labels, 'Count': counts}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    sns.barplot(x='Sentiment', y='Count', data=df, palette=colors, ax=ax)\n",
    "\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_title(f\"Sentiment Analysis for {ticker}\", fontsize=16)\n",
    "    ax.set_xlabel('Sentiment', fontsize=12)\n",
    "    ax.set_ylabel('Count', fontsize=12)\n",
    "\n",
    "    return sentiment_report, None,None, fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peer Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ychenoy/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import finnhub\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import torch\n",
    "from datetime import date, datetime, timedelta\n",
    "from collections import defaultdict\n",
    "from datasets import Dataset\n",
    "from openai import OpenAI\n",
    "from finnhub.client import FinnhubAPIException  # 导入异常类\n",
    "import gradio as gr\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
    "from pynvml import *\n",
    "\n",
    "finnhub_client = finnhub.Client(api_key=\"\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    '/finetuned_models/local-test_202412010011/checkpoint-24',\n",
    "    #token=access_token,\n",
    "    trust_remote_code=False, \n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    #offload_folder=\"offload/\"\n",
    ")\n",
    "\n",
    "model = model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    '/finetuned_models/local-test_202412010011/checkpoint-24',\n",
    "    #token=access_token\n",
    ")\n",
    "\n",
    "streamer = TextStreamer(tokenizer)\n",
    "\n",
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"You are a professional stock financial analyst. Your task is to analyze a target company and its industry peers based on relevant news \\nand basic financials for the last week, then provide company analysis, compare companies and determine the best-performing company. \" \\\n",
    "   \"Your answer format should be as follows:\\n\\n[Comparison Result (Best Company)]:...\\n\\n[Reasons]:1. ...\\n\\n[Peer Companies Analysis]:1. ...\\n\"\n",
    "def print_gpu_utilization():\n",
    "    \n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "\n",
    "def get_curday():\n",
    "    \n",
    "    return date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def n_weeks_before(date_string, n):\n",
    "    \n",
    "    date = datetime.strptime(date_string, \"%Y-%m-%d\") - timedelta(days=7*n)\n",
    "\n",
    "    return date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def get_stock_data(stock_symbol, steps):\n",
    "    try:\n",
    "        # 下载股票数据\n",
    "        stock_data = yf.download(stock_symbol, start=steps[0], end=steps[-1], progress=False)\n",
    "        if stock_data.empty:\n",
    "            print(f\"Warning: No data available for {stock_symbol}\")\n",
    "            return None  # 如果没有数据，返回 None\n",
    "\n",
    "        dates, prices = [], []\n",
    "        available_dates = stock_data.index.strftime(\"%Y-%m-%d\").tolist()  # 格式化日期为字符串\n",
    "\n",
    "        # 提取每个步骤的价格\n",
    "        for date in steps[:-1]:\n",
    "            matched = False\n",
    "            for i, available_date in enumerate(available_dates):\n",
    "                if available_date >= date:  # 找到最近的日期\n",
    "                    prices.append(stock_data['Close'].iloc[i])  # 追加收盘价\n",
    "                    dates.append(datetime.strptime(available_date, \"%Y-%m-%d\"))  # 转为 datetime\n",
    "                    matched = True\n",
    "                    break\n",
    "            if not matched:  # 如果没有匹配到\n",
    "                print(f\"Warning: No price data available for {stock_symbol} at step {date}\")\n",
    "                prices.append(None)\n",
    "                dates.append(datetime.strptime(date, \"%Y-%m-%d\"))\n",
    "\n",
    "        # 添加最后一天的数据\n",
    "        dates.append(datetime.strptime(available_dates[-1], \"%Y-%m-%d\"))\n",
    "        prices.append(stock_data['Close'].iloc[-1])\n",
    "\n",
    "        return pd.DataFrame({\n",
    "            \"Start Date\": dates[:-1],\n",
    "            \"End Date\": dates[1:],\n",
    "            \"Start Price\": prices[:-1],\n",
    "            \"End Price\": prices[1:]\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading data for {stock_symbol}: {e}\")\n",
    "        return None  # 捕获错误并返回 None\n",
    "\n",
    "def get_news(symbol, data):\n",
    "    \n",
    "    news_list = []\n",
    "    \n",
    "    for end_date, row in data.iterrows():\n",
    "        start_date = row['Start Date'].strftime('%Y-%m-%d')\n",
    "        end_date = row['End Date'].strftime('%Y-%m-%d')\n",
    "        print(symbol, ': ', start_date, ' - ', end_date)\n",
    "        #time.sleep(1) # control qpm\n",
    "        try:\n",
    "            weekly_news = finnhub_client.company_news(symbol, _from=start_date, to=end_date)\n",
    "            #print(len(weekly_news))\n",
    "            weekly_news_delet = weekly_news[:math.ceil(len(weekly_news)*0.01)]\n",
    "            #print(len(weekly_news_delet))\n",
    "            weekly_news_delet = [\n",
    "            {\n",
    "                \"date\": datetime.fromtimestamp(n['datetime']).strftime('%Y%m%d%H%M%S') if n['datetime'] > 0 else 'Invalid Date',\n",
    "                \"headline\": n['headline'],\n",
    "                \"summary\": n['summary'],\n",
    "            } for n in weekly_news_delet\n",
    "            ]\n",
    "            weekly_news_delet.sort(key=lambda x: x['date'])\n",
    "            news_list.append(json.dumps(weekly_news_delet))\n",
    "        except FinnhubAPIException as e:\n",
    "            news_list=[json.dumps([])]\n",
    "    \n",
    "    data['News'] = news_list\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_company_prompt(symbol):\n",
    "    try:\n",
    "        profile = finnhub_client.company_profile2(symbol=symbol)\n",
    "        if not profile:\n",
    "            raise gr.Error(f\"Failed to find company profile for symbol {symbol} from finnhub!\")\n",
    "            \n",
    "        company_template = \"[Company Introduction]:\\n\\n{name} is a leading entity in the {finnhubIndustry} sector. Incorporated and publicly traded since {ipo}, the company has established its reputation as one of the key players in the market. As of today, {name} has a market capitalization of {marketCapitalization:.2f} in {currency}, with {shareOutstanding:.2f} shares outstanding.\" \\\n",
    "            \"\\n\\n{name} operates primarily in the {country}, trading under the ticker {ticker} on the {exchange}. As a dominant force in the {finnhubIndustry} space, the company continues to innovate and drive progress within the industry.\"\n",
    "\n",
    "        formatted_str = company_template.format(**profile)\n",
    "\n",
    "    except FinnhubAPIException as e:\n",
    "        formatted_str = None \n",
    "    \n",
    "    \n",
    "    return formatted_str\n",
    "\n",
    "\n",
    "def get_prompt_by_row(symbol, row):\n",
    "\n",
    "    start_date = row['Start Date'] if isinstance(row['Start Date'], str) else row['Start Date'].strftime('%Y-%m-%d')\n",
    "    end_date = row['End Date'] if isinstance(row['End Date'], str) else row['End Date'].strftime('%Y-%m-%d')\n",
    "    #term = 'increased' if row['End Price'] > row['Start Price'] else 'decreased'\n",
    "    term = 'increased' if row['End Price'].iloc[0] > row['Start Price'].iloc[0] else 'decreased'\n",
    "    #head = \"From {} to {}, {}'s stock price {} from {:.2f} to {:.2f}. Company news during this period are listed below:\\n\\n\".format(\n",
    "    #    start_date, end_date, symbol, term, row['Start Price'], row['End Price'])\n",
    "    head = \"From {} to {}, {}'s stock price {} from {:.2f} to {:.2f}. Company news during this period are listed below:\\n\\n\".format(\n",
    "        start_date, end_date, symbol, term, row['Start Price'].iloc[0], row['End Price'].iloc[0])\n",
    "    \n",
    "    news = json.loads(row[\"News\"])\n",
    "    news = [\"[Headline]: {}\\n[Summary]: {}\\n\".format(\n",
    "        n['headline'], n['summary']) for n in news if n['date'][:8] <= end_date.replace('-', '') and \\\n",
    "        not n['summary'].startswith(\"Looking for stock market analysis and research with proves results?\")]\n",
    "\n",
    "    basics = json.loads(row['Basics'])\n",
    "    if basics:\n",
    "        basics = \"Some recent basic financials of {}, reported at {}, are presented below:\\n\\n[Basic Financials]:\\n\\n\".format(\n",
    "            symbol, basics['period']) + \"\\n\".join(f\"{k}: {v}\" for k, v in basics.items() if k != 'period')\n",
    "    else:\n",
    "        basics = \"[Basic Financials]:\\n\\nNo basic financial reported.\"\n",
    "    \n",
    "    return head, news, basics\n",
    "\n",
    "\n",
    "def sample_news(news, k=5):\n",
    "    \n",
    "    return [news[i] for i in sorted(random.sample(range(len(news)), k))]\n",
    "\n",
    "\n",
    "def get_current_basics(symbol, curday):\n",
    "\n",
    "    basic_financials = finnhub_client.company_basic_financials(symbol, 'all')\n",
    "    if not basic_financials['series']:\n",
    "        raise gr.Error(f\"Failed to find basic financials for symbol {symbol} from finnhub!\")\n",
    "        \n",
    "    final_basics, basic_list, basic_dict = [], [], defaultdict(dict)\n",
    "    \n",
    "    for metric, value_list in basic_financials['series']['quarterly'].items():\n",
    "        for value in value_list:\n",
    "            basic_dict[value['period']].update({metric: value['v']})\n",
    "\n",
    "    for k, v in basic_dict.items():\n",
    "        v.update({'period': k})\n",
    "        basic_list.append(v)\n",
    "        \n",
    "    basic_list.sort(key=lambda x: x['period'])\n",
    "    \n",
    "    for basic in basic_list[::-1]:\n",
    "        if basic['period'] <= curday:\n",
    "            break\n",
    "            \n",
    "    return basic\n",
    "    \n",
    "\n",
    "def get_all_prompts_online(symbol, data, curday, with_basics=True):\n",
    "\n",
    "    company_prompt = get_company_prompt(symbol)\n",
    "    if company_prompt is None:\n",
    "        return None, None\n",
    "    else:\n",
    "        prev_rows = []\n",
    "\n",
    "        for row_idx, row in data.iterrows():\n",
    "            head, news, _ = get_prompt_by_row(symbol, row)\n",
    "            prev_rows.append((head, news, None))\n",
    "            \n",
    "        prompt = \"\"\n",
    "        for i in range(-len(prev_rows), 0):\n",
    "            prompt += \"\\n\" + prev_rows[i][0]\n",
    "            sampled_news = sample_news(\n",
    "                prev_rows[i][1],\n",
    "                min(5, len(prev_rows[i][1]))\n",
    "            )\n",
    "            if sampled_news:\n",
    "                prompt += \"\\n\".join(sampled_news)\n",
    "            else:\n",
    "                prompt += \"No relative news reported.\"\n",
    "            \n",
    "        period = \"{} to {}\".format(curday, n_weeks_before(curday, -1))\n",
    "        \n",
    "        if with_basics:\n",
    "            basics = get_current_basics(symbol, curday)\n",
    "            basics = \"Some recent basic financials of {}, reported at {}, are presented below:\\n\\n[Basic Financials]:\\n\\n\".format(\n",
    "                symbol, basics['period']) + \"\\n\".join(f\"{k}: {v}\" for k, v in basics.items() if k != 'period')\n",
    "        else:\n",
    "            basics = \"[Basic Financials]:\\n\\nNo basic financial reported.\"\n",
    "\n",
    "        info = company_prompt + '\\n' + prompt + '\\n' + basics\n",
    "        prompt = info + f\"\\n\\nBased on all the information before {curday}, let's first analyze the positive developments and potential concerns for {symbol}. Come up with 2-4 most important factors respectively and keep them concise. Most factors should be inferred from company related news. \" \\\n",
    "            f\"Then make your prediction of the {symbol} stock price movement for next week ({period}). Provide a summary analysis to support your prediction.\"\n",
    "            \n",
    "        return info, prompt\n",
    "\n",
    "\n",
    "def construct_prompt(ticker, curday, n_weeks, use_basics):\n",
    "\n",
    "    '''\n",
    "    try:\n",
    "        steps = [n_weeks_before(curday, n) for n in range(n_weeks + 1)][::-1]\n",
    "    except Exception:\n",
    "        raise gr.Error(f\"Invalid date {curday}!\")\n",
    "        \n",
    "    '''\n",
    "    steps = [n_weeks_before(curday, n) for n in range(n_weeks + 1)][::-1]\n",
    "    data = get_stock_data(ticker, steps)\n",
    "    if data is None:\n",
    "        return None, None\n",
    "    else:\n",
    "        data = get_news(ticker, data)\n",
    "        data['Basics'] = [json.dumps({})] * len(data)\n",
    "        # print(data)\n",
    "        \n",
    "        info, prompt = get_all_prompts_online(ticker, data, curday, use_basics)\n",
    "        if info is None:\n",
    "            return None, None\n",
    "        else:\n",
    "            #prompt = B_INST + B_SYS + SYSTEM_PROMPT + E_SYS + prompt + E_INST\n",
    "            return info, prompt\n",
    "\n",
    "def predict_compare(ticker, curday, use_basics=False):\n",
    "\n",
    "   \n",
    "    # 获取特定ticker的同行公司\n",
    "    peers_lst = finnhub_client.company_peers(ticker)\n",
    "    # system prompt\n",
    "    #SYSTEM_PROMPT = \"You are an expert financial analyst. Please provide a detailed comparison of the following companies.\"\n",
    "\n",
    "    if not peers_lst:\n",
    "        raise gr.Error(f\"Failed to find peer companies for symbol {ticker} from finnhub!\")\n",
    "\n",
    "    # 获取目标公司（如TSLA）的分析\n",
    "    company_info, company_prompt = construct_prompt(ticker, curday, n_weeks=1, use_basics=use_basics)\n",
    "    \n",
    "    # 初始化对比分析的prompt\n",
    "    company_info += f\"\\n\\nThe following are the information of peer companis:\"\n",
    "    comparison_prompt = f\"Below is the analysis of {ticker}. Please compare this company with its peers and give your analysis on which one is the best based on the following dimensions:\\n1. Financial performance\\n2. Market trends and news\\n3. Stock price movement prediction\\n\\n{company_prompt}\\n\\n\"\n",
    "\n",
    "    # 对每个同行公司进行分析，并构建对比prompt\n",
    "    count = 0\n",
    "    for peer in peers_lst[1:]:\n",
    "        if count < 3:\n",
    "            peer_info, peer_prompt = construct_prompt(peer, curday,n_weeks=1, use_basics=use_basics)\n",
    "            if peer_info is None:\n",
    "                continue\n",
    "            company_info += f\"\\n\\n{peer_info}\"\n",
    "            comparison_prompt += f\"\\n\\n[Analysis of {peer}]:\\n{peer_prompt}\"\n",
    "            count+=1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    # 生成模型输入\n",
    "    comparison_prompt = B_INST + B_SYS + SYSTEM_PROMPT + E_SYS + comparison_prompt + E_INST\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        comparison_prompt, return_tensors='pt', padding=False\n",
    "    )\n",
    "    inputs = {key: value.to(model.device) for key, value in inputs.items()}\n",
    "\n",
    "    print(\"Inputs loaded onto devices.\")\n",
    "\n",
    "    res = model.generate(\n",
    "        **inputs, max_length=4096*30, do_sample=True,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        use_cache=True\n",
    "    )   \n",
    "    output = tokenizer.decode(res[0], skip_special_tokens=True)\n",
    "    answer = re.sub(r'.*\\[/INST\\]\\s*', '', output, flags=re.DOTALL)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return company_info, answer, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyst Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 17:37:20.911233: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-03 17:37:20.926188: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733218640.943403  567104 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733218640.948483  567104 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-03 17:37:20.967020: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import finnhub\n",
    "import torch\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from pynvml import *\n",
    "from peft import PeftModel\n",
    "from collections import defaultdict\n",
    "from datetime import date, datetime, timedelta\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"FINNHUB_API_KEY\"] = \"\"\n",
    "finnhub_client = finnhub.Client(api_key=os.environ[\"FINNHUB_API_KEY\"])\n",
    "\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    \n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")  \n",
    "\n",
    "# Define the plot_recommendation_trends function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import finnhub\n",
    "\n",
    "\n",
    "# Define the plot_recommendation_trends function\n",
    "def plot_recommendation_trends(symbol, n_months=4):\n",
    "    data = finnhub_client.recommendation_trends(symbol) \n",
    "\n",
    "    # Extract data\n",
    "    periods = [entry['period'] for entry in data][:n_months]\n",
    "    buy = [entry['buy'] for entry in data][:n_months]\n",
    "    hold = [entry['hold'] for entry in data][:n_months]\n",
    "    sell = [entry['sell'] for entry in data][:n_months]\n",
    "    strong_buy = [entry['strongBuy'] for entry in data][:n_months]\n",
    "    strong_sell = [entry['strongSell'] for entry in data][:n_months]\n",
    "\n",
    "    # Convert dates to month + year format\n",
    "    periods_formatted = [datetime.strptime(period, '%Y-%m-%d').strftime('%B %Y') for period in periods]\n",
    "\n",
    "    # Set background color and grid\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    # Plot the chart\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(len(periods))\n",
    "\n",
    "    bars5 = plt.bar(index, strong_sell, bar_width, label='Strong Sell', color='#8B0000')\n",
    "    bars4 = plt.bar(index, sell, bar_width, bottom=strong_sell, label='Sell', color='#FF6347')\n",
    "    bars3 = plt.bar(index, hold, bar_width, bottom=[i+j for i,j in zip(strong_sell, sell)], label='Hold', color='#FFA500')\n",
    "    bars2 = plt.bar(index, buy, bar_width, bottom=[i+j+k for i,j,k in zip(strong_sell, sell, hold)], label='Buy', color='#008000')\n",
    "    bars1 = plt.bar(index, strong_buy, bar_width, bottom=[i+j+k+l for i,j,k,l in zip(strong_sell, sell, hold, buy)], label='Strong Buy', color='#006400')\n",
    "\n",
    "    # Add numbers to each bar\n",
    "    for bar in bars1:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2.0,\n",
    "                 strong_sell[bars1.index(bar)] + sell[bars1.index(bar)] + hold[bars1.index(bar)] + buy[bars1.index(bar)] + height / 2.0,\n",
    "                 '%d' % int(height), ha='center', va='bottom', color='white')\n",
    "\n",
    "    for bar in bars2:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2.0,\n",
    "                 strong_sell[bars2.index(bar)] + sell[bars2.index(bar)] + hold[bars2.index(bar)] + height / 2.0,\n",
    "                 '%d' % int(height), ha='center', va='bottom', color='white')\n",
    "\n",
    "    for bar in bars3:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2.0,\n",
    "                 strong_sell[bars3.index(bar)] + sell[bars3.index(bar)] + height / 2.0,\n",
    "                 '%d' % int(height), ha='center', va='bottom', color='white')\n",
    "\n",
    "    for bar in bars4:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2.0,\n",
    "                 strong_sell[bars4.index(bar)] + height / 2.0,\n",
    "                 '%d' % int(height), ha='center', va='bottom', color='white')\n",
    "\n",
    "    for bar in bars5:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2.0,\n",
    "                 height / 2.0,\n",
    "                 '%d' % int(height), ha='center', va='bottom', color='white')\n",
    "\n",
    "    # Set axis labels and title\n",
    "    plt.xlabel('Period', fontsize=12)\n",
    "    plt.ylabel('#Analysts', fontsize=12)\n",
    "    plt.title(f'{symbol} Stock Recommendations Trends', fontsize=14)\n",
    "    plt.xticks(index, periods_formatted)\n",
    "    \n",
    "    # Calculate the maximum value among all the bars and set y-axis limit slightly higher than the maximum value\n",
    "    max_value = max([sum(x) for x in zip(strong_sell, sell, hold, buy, strong_buy)])\n",
    "    plt.ylim(0, max_value * 1.1)  # Modify y-axis range to be slightly higher than the maximum value\n",
    "    \n",
    "    plt.legend()\n",
    "\n",
    "    # Save the chart as an image file\n",
    "    image_path = f\"{symbol}_recommendation_trends.png\"\n",
    "    plt.savefig(image_path)\n",
    "\n",
    "    # Output the number of analysts recommending buy, sell, etc. for each month\n",
    "    output = \"\"\n",
    "    for i in range(len(periods)):\n",
    "        output += f\"{periods_formatted[i]}: {strong_buy[i]} Strong Buy, {buy[i]} Buy, {hold[i]} Hold, {sell[i]} Sell, {strong_sell[i]} Strong Sell\\n\"\n",
    "    \n",
    "    return output, image_path\n",
    "\n",
    "# predict\n",
    "def predict_rating(ticker, n_months):\n",
    "    \n",
    "    print_gpu_utilization()\n",
    "    \n",
    "    recommend_output, image_path = plot_recommendation_trends(ticker, n_months)\n",
    "\n",
    "    return recommend_output, None, image_path, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict_final and demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict_final(model_choice , ticker, date, n_weeks, use_latest_financials):\n",
    "    if model_choice == \"Forcaster\":\n",
    "        return predict_forecast(ticker, date, n_weeks, use_latest_financials)  # 传递 model_choice\n",
    "    elif model_choice == \"Portfolio Manager\":\n",
    "        return predict_strategy(ticker, date, n_weeks, use_latest_financials)\n",
    "    elif model_choice == \"Sentiment Analysis\":\n",
    "        return predict_sentiment(ticker, date, n_weeks)\n",
    "    elif model_choice == \"Peer Comparison\":\n",
    "        return predict_compare(ticker, date, use_latest_financials)\n",
    "    elif model_choice == \"Rating Analysis\":\n",
    "        return predict_rating(ticker, n_weeks)\n",
    "    else:\n",
    "        return \"Please choose a model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://c1f9e9de28605bd58d.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c1f9e9de28605bd58d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 4317 MB.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def update_inputs(selected_model):\n",
    "    if selected_model == \"Forcaster\":\n",
    "        show_choice = True\n",
    "        show_ticker = True\n",
    "        show_date = True\n",
    "        show_n_weeks = True\n",
    "        show_latest_financials = True\n",
    "        n_weeks_label = \"n_weeks\"\n",
    "    elif selected_model == \"Portfolio Manager\":\n",
    "        show_choice = True\n",
    "        show_ticker = True\n",
    "        show_date = True\n",
    "        show_n_weeks = True\n",
    "        show_latest_financials = True\n",
    "        n_weeks_label = \"n_weeks\"\n",
    "    elif selected_model == \"Peer Comparison\":\n",
    "        show_choice = True\n",
    "        show_ticker = True\n",
    "        show_date = True\n",
    "        show_n_weeks = False\n",
    "        show_latest_financials = True\n",
    "        n_weeks_label = \"n_weeks\"\n",
    "    elif selected_model == \"Sentiment Analysis\":\n",
    "        show_choice = True\n",
    "        show_ticker = True\n",
    "        show_date = True\n",
    "        show_n_weeks = True\n",
    "        show_latest_financials = False\n",
    "        n_weeks_label = \"n_weeks\"\n",
    "    elif selected_model == \"Rating Analysis\":\n",
    "        show_choice = True\n",
    "        show_ticker = True\n",
    "        show_date = False\n",
    "        show_n_weeks = True\n",
    "        n_weeks_label = \"n_months\"\n",
    "        show_latest_financials = False\n",
    "\n",
    "    return (gr.update(visible=show_choice),\n",
    "            gr.update(visible=show_ticker),\n",
    "            gr.update(visible=show_date),\n",
    "            gr.update(visible=show_n_weeks, label=n_weeks_label),\n",
    "            gr.update(visible=show_latest_financials))\n",
    "\n",
    "def update_outputs(selected_model):\n",
    "    show_information = True\n",
    "    show_response = True\n",
    "    show_image_output = False\n",
    "    show_plot_output = False\n",
    "\n",
    "    if selected_model == \"Forcaster\":\n",
    "        show_information = True\n",
    "        show_response = True\n",
    "        show_image_output = False\n",
    "        show_plot_output = False\n",
    "    elif selected_model == \"Portfolio Manager\":\n",
    "        show_information = True\n",
    "        show_response = True\n",
    "        show_image_output = False\n",
    "        show_plot_output = False\n",
    "    elif selected_model == \"Peer Comparison\":\n",
    "        show_information = True\n",
    "        show_response = True\n",
    "        show_image_output = False\n",
    "        show_plot_output = False\n",
    "    elif selected_model == \"Sentiment Analysis\":\n",
    "        show_information = True\n",
    "        show_response = False\n",
    "        show_image_output = False\n",
    "        show_plot_output = True\n",
    "    elif selected_model == \"Rating Analysis\":\n",
    "        show_information = True\n",
    "        show_response = False\n",
    "        show_image_output = True\n",
    "        show_plot_output = False\n",
    "\n",
    "    return (gr.update(visible=show_information),\n",
    "            gr.update(visible=show_response),\n",
    "            gr.update(visible=show_image_output),\n",
    "            gr.update(visible=show_plot_output))\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    # Add the title inside the layout and add the description as Markdown\n",
    "    gr.Markdown(\"\"\"\n",
    "    <h1 style=\"text-align: center;\">FinGPT</h1>\n",
    "                \n",
    "    Our FinGPT is a kind of financial analyst assistant having five functions: \n",
    "                **Forcastor, Portfolio Manager, Peer Comparison, Sentiment Analysis, and Rating Analysis.**\n",
    "    All the analysis are based on company profiles, market news and optional basic financials retrieved from **yfinance & finnhub**.\n",
    "    The models are finetuned on Llama2-7b-chat-hf with LoRA on the past year's DOW30 market data. Inference in this demo uses fp16 and **welcomes any ticker symbol**.\n",
    "    \n",
    "    **Disclaimer: Nothing herein is financial advice, and NOT a recommendation to trade real money. Please use common sense and always first consult a professional before trading or investing.**\n",
    "    \"\"\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            prediction_model = gr.Dropdown(\n",
    "                label=\"Model Choice\",\n",
    "                choices=[\"Forcaster\", \"Portfolio Manager\", \"Peer Comparison\", \"Sentiment Analysis\", \"Rating Analysis\"],\n",
    "                value=\"Forcaster\",\n",
    "                info=\"Choose the model you want to use\",\n",
    "            )\n",
    "\n",
    "            ticker = gr.Textbox(label=\"Ticker\", value=\"TSLA\", info=\"Companies that you can get information from Finnhub\")\n",
    "            date_text = gr.Textbox(label=\"Date\", value='2024-05-31', info=\"Date from which the prediction is made, use format yyyy-mm-dd\")\n",
    "\n",
    "            n_weeks_slider = gr.Slider(\n",
    "                minimum=1,\n",
    "                maximum=4,\n",
    "                value=1,\n",
    "                step=1,\n",
    "                label=\"n_weeks\",\n",
    "                info=\"Information of the past n weeks will be utilized, choose between 1 and 4\",\n",
    "            )\n",
    "\n",
    "            use_latest_financials = gr.Checkbox(label=\"Use Latest Basic Financials\", value=False, info=\"If checked, the latest quarterly reported basic financials of the company are taken into account.\")\n",
    "\n",
    "            # Add callback for model choice\n",
    "            prediction_model.change(fn=update_inputs, inputs=prediction_model, outputs=[prediction_model, ticker, date_text, n_weeks_slider, use_latest_financials])\n",
    "            submit_button = gr.Button(\"Submit\")\n",
    "\n",
    "\n",
    "        with gr.Column():\n",
    "            information = gr.Textbox(label=\"Information\", visible=True)  # Default visible\n",
    "            response = gr.Textbox(label=\"Response\", visible=True)  # Default visible\n",
    "            image_output = gr.Image(label=\"Output Image\", visible=False)  # Default hidden\n",
    "            plot_output = gr.Plot(label=\"Output Image\", visible=False)\n",
    "\n",
    "            # Add callback for model choice\n",
    "            prediction_model.change(fn=update_outputs, inputs=prediction_model, outputs=[information, response, image_output, plot_output])\n",
    "\n",
    "        submit_button.click(fn=predict_final, inputs=[prediction_model, ticker, date_text, n_weeks_slider, use_latest_financials], \n",
    "                            outputs=[information, response, image_output, plot_output])\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galaxy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
